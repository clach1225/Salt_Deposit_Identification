{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "import keras.utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the Data to be Trained and Labeled.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "X_images = []\n",
    "y_images = []\n",
    "\n",
    "#Data Paths\n",
    "train_image_path = r\"C:\\Users\\uschlac\\Documents\\Practicum\\Practicum_2\\images\"\n",
    "train_mask_path = r\"C:\\Users\\uschlac\\Documents\\Practicum\\Practicum_2\\masks\"\n",
    "\n",
    "\n",
    "image_list = os.listdir(train_image_path)\n",
    "mask_list = os.listdir(train_mask_path)\n",
    "\n",
    "for image_num in range(len(image_list)):\n",
    "    #Gets the Path to the Mask\n",
    "    certain_image_path = os.path.join(train_image_path, image_list[image_num])\n",
    "    image_img = Image.open(certain_image_path).convert('L')\n",
    "    image_pix = np.array(image_img.getdata()).reshape(image_img.size[0], image_img.size[1], 1)\n",
    "    X.append(image_pix)\n",
    "    X_images.append(image_img)\n",
    "\n",
    "for mask_num in range(len(mask_list)):\n",
    "    #Gets the Path to the Mask\n",
    "    certain_mask_path = os.path.join(train_mask_path, mask_list[mask_num])\n",
    "    mask_img = Image.open(certain_mask_path).convert('L')\n",
    "    mask_pix = np.array(mask_img.getdata()).reshape(mask_img.size[0], mask_img.size[1], 1)\n",
    "    y.append(mask_pix)\n",
    "    y_images.append(mask_img)\n",
    "    \n",
    "X = np.array(X, dtype = 'float32')\n",
    "y = np.array(y, dtype = 'float32')\n",
    "\n",
    "#Convert pixel values between 0 and 1. \n",
    "X = np.divide(X, 255)\n",
    "y = np.divide(y, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=101x101 at 0x12738320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGUAAABlCAAAAABxF3ITAAAA5ElEQVR4nO2Zyw7DIAwEl6r//8v00ChpXhJrAlro7hEkj8bGJ1LGIQkATqfrTSjv08kloDKvBjVHoMR7SbmEMVzHohi9uSAsw7rEMJIdM8WUWSihtRR1mYoSGYyqy1SUwGBkXaai8IPRdZmKQg9G2MWUv6awT1nZhZWRdjGFDjd+bRdTRCnUIxN3MYUOM/4KFwKj3jFTTDGFSfny67t0ohS3bACXYpnzD29lvuDDl3Oq/TZOyL9F83r8KGUrmnfFdpiHKHfkJQ3fWN4EGrosAKDDvmSggwuAMXbfFFNMMcUUU67zAeQ5I7HCfT4XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=101x101 at 0x1B73BBE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is how data looks. \n",
    "#The top is the what we need to seperate salt from sediment.\n",
    "#The bottom is the mask or label we need to predict. \n",
    "display(X_images[10], y_images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 101, 101, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 101, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uschlac\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 101, 101, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.backend.tensorflow_backend.clear_session()>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "# hint: you need Flatten() before the first dense layer\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(1, kernel_size = (1,1), activation = 'relu', input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# build the model\n",
    "model = simple_cnn_model()\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "t0 = time.time()\n",
    "log = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "t1 = time.time()\n",
    "print(t1-t0, \" seconds\")\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as KerasBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(y_true,y_pred):\n",
    "    keras.backend.tf.metrics.mean_iou(y_true,y_pred,num_classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.tf.metrics.mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = np.multiply(preds[0], 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('sample',pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "# # build the model\n",
    "# model = simple_cnn_model()\n",
    "\n",
    "# # Fit the model\n",
    "\n",
    "# t0 = time.time()\n",
    "# log = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "# t1 = time.time()\n",
    "# print(t1-t0, \" seconds\")\n",
    "# # Final evaluation of the model\n",
    "# scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "# print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_val)\n",
    "preds = np.multiply(preds, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1301].max()\n",
    "pred = preds[1301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('l' , np.array(pred, dtype = np.uint8 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=r\"C:\\Users\\buckf\\Documents\\Practicum_2\\Presentation_Photos\\Network_Structure.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 101, 101, 50)      500       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 101, 101, 50)      22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 33, 33, 50)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 35, 35, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 35, 35, 50)        22550     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 35, 35, 50)        22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 11, 11, 1)         451       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 33, 33, 1)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 99, 99, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 101, 101, 1)       0         \n",
      "=================================================================\n",
      "Total params: 68,601\n",
      "Trainable params: 68,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1932 - acc: 0.7471 - val_loss: 0.1597 - val_acc: 0.7659\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.1477 - acc: 0.7893 - val_loss: 0.1467 - val_acc: 0.8338\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1224 - acc: 0.8426 - val_loss: 0.1531 - val_acc: 0.7653\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1189 - acc: 0.8499 - val_loss: 0.1073 - val_acc: 0.8684\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1127 - acc: 0.8587 - val_loss: 0.1061 - val_acc: 0.8719\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1054 - acc: 0.8698 - val_loss: 0.1004 - val_acc: 0.8759\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1027 - acc: 0.8726 - val_loss: 0.1032 - val_acc: 0.8693\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0984 - acc: 0.8784 - val_loss: 0.1015 - val_acc: 0.8765\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0960 - acc: 0.8828 - val_loss: 0.1086 - val_acc: 0.8637\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0923 - acc: 0.8859 - val_loss: 0.0933 - val_acc: 0.8836\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0917 - acc: 0.8858 - val_loss: 0.0912 - val_acc: 0.8841\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0887 - acc: 0.8893 - val_loss: 0.1001 - val_acc: 0.8771\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0901 - acc: 0.8885 - val_loss: 0.0915 - val_acc: 0.8835\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0867 - acc: 0.8926 - val_loss: 0.1163 - val_acc: 0.8438\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0876 - acc: 0.8902 - val_loss: 0.0973 - val_acc: 0.8785\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0840 - acc: 0.8951 - val_loss: 0.0889 - val_acc: 0.8899\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0850 - acc: 0.8951 - val_loss: 0.0873 - val_acc: 0.8880\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0842 - acc: 0.8969 - val_loss: 0.0857 - val_acc: 0.8905\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0807 - acc: 0.8999 - val_loss: 0.0817 - val_acc: 0.8964\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0813 - acc: 0.8992 - val_loss: 0.0852 - val_acc: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8fcf98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #Convolution 1:\n",
    "    model.add(Conv2D(50, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "    \n",
    "    #Convolution 2:\n",
    "    model.add(Conv2D(50, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    \n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    \n",
    "    #Convolution 3\n",
    "    model.add(Conv2D(50, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #Convolution 4\n",
    "    model.add(Conv2D(50, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #Max-Pool 2\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(1, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    \n",
    "    model.add(UpSampling2D(size=(3,3)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(UpSampling2D(size=(3,3)))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.2338571 ],\n",
       "         [0.2338571 ],\n",
       "         ...,\n",
       "         [0.02833684],\n",
       "         [0.02833684],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.2338571 ],\n",
       "         [0.2338571 ],\n",
       "         ...,\n",
       "         [0.02833684],\n",
       "         [0.02833684],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.14817777],\n",
       "         [0.14817777],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.14817777],\n",
       "         [0.14817777],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.39296028],\n",
       "         [0.39296028],\n",
       "         ...,\n",
       "         [0.23498371],\n",
       "         [0.23498371],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.39296028],\n",
       "         [0.39296028],\n",
       "         ...,\n",
       "         [0.23498371],\n",
       "         [0.23498371],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.35317004],\n",
       "         [0.35317004],\n",
       "         ...,\n",
       "         [0.17301416],\n",
       "         [0.17301416],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.35317004],\n",
       "         [0.35317004],\n",
       "         ...,\n",
       "         [0.17301416],\n",
       "         [0.17301416],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.20539626],\n",
       "         [0.20539626],\n",
       "         ...,\n",
       "         [0.4158294 ],\n",
       "         [0.4158294 ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.20539626],\n",
       "         [0.20539626],\n",
       "         ...,\n",
       "         [0.4158294 ],\n",
       "         [0.4158294 ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.94259965],\n",
       "         [0.94259965],\n",
       "         ...,\n",
       "         [0.904375  ],\n",
       "         [0.904375  ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.94259965],\n",
       "         [0.94259965],\n",
       "         ...,\n",
       "         [0.904375  ],\n",
       "         [0.904375  ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.27713317],\n",
       "         [0.27713317],\n",
       "         ...,\n",
       "         [0.11918051],\n",
       "         [0.11918051],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.27713317],\n",
       "         [0.27713317],\n",
       "         ...,\n",
       "         [0.11918051],\n",
       "         [0.11918051],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.14706461],\n",
       "         [0.14706461],\n",
       "         ...,\n",
       "         [0.18102786],\n",
       "         [0.18102786],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.14706461],\n",
       "         [0.14706461],\n",
       "         ...,\n",
       "         [0.18102786],\n",
       "         [0.18102786],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.0502213 ],\n",
       "         [0.0502213 ],\n",
       "         ...,\n",
       "         [0.17330676],\n",
       "         [0.17330676],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.0502213 ],\n",
       "         [0.0502213 ],\n",
       "         ...,\n",
       "         [0.17330676],\n",
       "         [0.17330676],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.17390582],\n",
       "         [0.17390582],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.17390582],\n",
       "         [0.17390582],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.30588448],\n",
       "         [0.30588448],\n",
       "         ...,\n",
       "         [0.18544614],\n",
       "         [0.18544614],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.30588448],\n",
       "         [0.30588448],\n",
       "         ...,\n",
       "         [0.18544614],\n",
       "         [0.18544614],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utf8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4e89cc1bd7c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutf8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'utf8' is not defined"
     ]
    }
   ],
   "source": [
    "preds.astype(utf8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = pred.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.multiply(pred, 255)\n",
    "pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('sample', pred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "# # build the model\n",
    "# model = simple_cnn_model()\n",
    "\n",
    "# # Fit the model\n",
    "\n",
    "# t0 = time.time()\n",
    "# log = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "# t1 = time.time()\n",
    "# print(t1-t0, \" seconds\")\n",
    "# # Final evaluation of the model\n",
    "# scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "# print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score.py\n",
    "import os\n",
    "#import settings\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import metrics\n",
    "from keras.models import Model, load_model\n",
    "from skimage.morphology import label\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Settings\n",
    "max_number_of_samples = 50 # this sets how many samples of the full training set to look at, this is not random, just the first N samples\n",
    "model_file = \"model-dsbowl2018-3.h5\"\n",
    "X_train_file = \"X_train_256_256.npy\"\n",
    "\n",
    "# Define the object by object mean IOU calculation for a given image\n",
    "def object_mean_iou(y_labeled_true, y_labeled_pred):\n",
    "    num_y_labeled_true = y_labeled_true.max()\n",
    "    num_y_labeled_pred = y_labeled_pred.max()\n",
    "    threshold_ious = []\n",
    "    for threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:\n",
    "        true_positives = 0\n",
    "        false_negative = 0\n",
    "        pred_obj_preload = []\n",
    "        pred_obj_size = []\n",
    "        for predicted_object_id in range(1, num_y_labeled_pred + 1):\n",
    "            pred_obj = y_labeled_pred == predicted_object_id\n",
    "            pred_obj_preload.append(pred_obj)\n",
    "            pred_obj_size.append(np.count_nonzero(pred_obj))\n",
    "        # a true positive for given threshold is when a _single_ object in the prediction corresponds to a given true object\n",
    "        for true_object_id in range(1, num_y_labeled_true + 1):\n",
    "            true_obj = y_labeled_true == true_object_id\n",
    "            true_obj_size = np.count_nonzero(true_obj)\n",
    "            matches = 0\n",
    "            for predicted_object_id in range(1, num_y_labeled_pred + 1):\n",
    "                # calculate the iou for this object and the true object\n",
    "                this_pred_obj = pred_obj_preload[predicted_object_id-1]\n",
    "                this_pred_obj_size = pred_obj_size[predicted_object_id-1]\n",
    "                intersection = np.count_nonzero(true_obj & this_pred_obj)\n",
    "                union = true_obj_size + this_pred_obj_size - intersection\n",
    "                iou = intersection / union\n",
    "                if iou > threshold:\n",
    "                    matches += 1\n",
    "            if matches == 1:\n",
    "                true_positives += 1\n",
    "            if matches == 0:\n",
    "                false_negative += 1\n",
    "        false_positive = num_y_labeled_pred - true_positives\n",
    "        threshold_ious.append(true_positives / (true_positives + false_positive + false_negative))\n",
    "    return sum(threshold_ious) / len(threshold_ious)\n",
    "\n",
    "train_ids = next(os.walk(settings.TRAIN_PATH))[1][:max_number_of_samples]\n",
    "# this is the 256x256 training data already loaded into a numpy array and resized\n",
    "X_train = np.load(X_train_file)[:max_number_of_samples]\n",
    "# this is the true sizes of the training images for upsampling the masks after prediction\n",
    "sizes_train = np.load(\"sizes_train.npy\")\n",
    "\n",
    "# Get and resize train images and masks\n",
    "Y_labeled_true = []\n",
    "IMG_CHANNELS = settings.IMG_CHANNELS\n",
    "print('Loading true masks ...')\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = settings.TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    mask = np.zeros((img.shape[0], img.shape[1], 1), dtype=np.bool)\n",
    "    next_object_number = 1\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = next_object_number * (np.expand_dims(mask_, axis=-1) // 255)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "        next_object_number += 1\n",
    "    Y_labeled_true.append(np.squeeze(mask, -1))\n",
    "\n",
    "# Use the same labeling methodology here that you use before submitting\n",
    "model = load_model(model_file, custom_objects={\"mean_iou\": metrics.mean_iou, \"mean_iou2\": metrics.mean_iou2})\n",
    "preds_train = model.predict(X_train, verbose=1)\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_train_t)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_train_t[i]), \n",
    "                                       (sizes_train[i][0], sizes_train[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n",
    "Y_labeled_pred = [label(pred) for pred in preds_test_upsampled]\n",
    "\n",
    "images_iou = []\n",
    "for n in range(len(Y_labeled_true)):\n",
    "    image_iou = object_mean_iou(Y_labeled_true[n], Y_labeled_pred[n])\n",
    "    print(\"Image \" + str(n) + \" IOU: \" + str(image_iou))\n",
    "    images_iou.append(image_iou)\n",
    "print(\"mIOU (LB) Score: \" + str(sum(images_iou) / len(images_iou)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "# # build the model\n",
    "# model = simple_cnn_model()\n",
    "\n",
    "# # Fit the model\n",
    "\n",
    "# t0 = time.time()\n",
    "# log = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "# t1 = time.time()\n",
    "# print(t1-t0, \" seconds\")\n",
    "# # Final evaluation of the model\n",
    "# scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "# print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
