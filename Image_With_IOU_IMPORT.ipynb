{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\buckf\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "import keras.backend as KerasBackend\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IOU import iou_metric,iou_metric_batch,my_iou_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the Data to be Trained and Labeled.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "X_images = []\n",
    "y_images = []\n",
    "\n",
    "#Data Paths\n",
    "train_image_path = r\"C:\\Users\\buckf\\Documents\\Practicum_2\\Data\\train\\images\"\n",
    "train_mask_path = r\"C:\\Users\\buckf\\Documents\\Practicum_2\\Data\\train\\masks\"\n",
    "\n",
    "\n",
    "image_list = os.listdir(train_image_path)\n",
    "mask_list = os.listdir(train_mask_path)\n",
    "\n",
    "for image_num in range(len(image_list)):\n",
    "    #Gets the Path to the Mask\n",
    "    certain_image_path = os.path.join(train_image_path, image_list[image_num])\n",
    "    image_img = Image.open(certain_image_path).convert('L')\n",
    "    image_pix = np.array(image_img.getdata()).reshape(image_img.size[0], image_img.size[1], 1)\n",
    "    X.append(image_pix)\n",
    "    X_images.append(image_img)\n",
    "\n",
    "for mask_num in range(len(mask_list)):\n",
    "    #Gets the Path to the Mask\n",
    "    certain_mask_path = os.path.join(train_mask_path, mask_list[mask_num])\n",
    "    mask_img = Image.open(certain_mask_path).convert('L')\n",
    "    mask_pix = np.array(mask_img.getdata()).reshape(mask_img.size[0], mask_img.size[1], 1)\n",
    "    y.append(mask_pix)\n",
    "    y_images.append(mask_img)\n",
    "    \n",
    "X = np.array(X, dtype = 'uint8')\n",
    "y = np.array(y, dtype = 'uint8')\n",
    "\n",
    "\n",
    "#Convert pixel values between 0 and 1. \n",
    "X = np.divide(X, 255)\n",
    "y = np.divide(y, 255)\n",
    "\n",
    "#Covert Datatype of Arrays for openCV and IoU functions.\n",
    "X = X.astype('uint8')\n",
    "y = y.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\buckf\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 101, 101, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 101, 101, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 101, 101, 1)       289       \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/6\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.1915 - mean_iou: 0.3809"
     ]
    }
   ],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error, optimizer= 'adam' , metrics=[mean_iou])\n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "#model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "log = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=6, batch_size=15, verbose=1)\n",
    "t1 = time.time()\n",
    "print(t1-t0, \" seconds\")\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "print(\"Average MSE LOSS: \" + str(scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error, optimizer= 'adam' , metrics=[my_iou_metric])\n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "#model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "log = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=6, batch_size=15, verbose=1)\n",
    "t1 = time.time()\n",
    "print(t1-t0, \" seconds\")\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "print(\"Average MSE LOSS: \" + str(scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D(padding=(2,2), input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "    \n",
    "    #Convolution 1:\n",
    "    model.add(Conv2D(50, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same'))\n",
    "    \n",
    "    #Convolution 2:\n",
    "    model.add(Conv2D(50, kernel_size= (2,2), activation='relu', padding='same'))\n",
    "    \n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Convolution 3\n",
    "    model.add(Conv2D(50, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #Convolution 4\n",
    "    model.add(Conv2D(50, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #Max-Pool 2\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(1, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    \n",
    "    model.add(UpSampling2D(size=(3,3)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(UpSampling2D(size=(3,3)))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error, optimizer= 'adam' , metrics=[my_iou_metric])\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = y_val.shape[1]\n",
    "\n",
    "def simple_cnn_model():\n",
    "    \n",
    "    # create model\n",
    "### YOUR TURN\n",
    "# Build a model that has 1 convolution layer, 1 max pooling, 1 dense, and output \n",
    "# Use 32 filters with 5x5 size\n",
    "# For max pooling layer, make the layer such that the featuremap size would be the half after the pooling layer\n",
    "# hint: you need to change the argument input_shape to (w,h,1) in the first conv layer\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D(padding=(2,2), input_shape = (X_train.shape[1], X_train.shape[2], 1)))\n",
    "    \n",
    "    #Convolution 1:\n",
    "    model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same'))\n",
    "    \n",
    "    #Convolution 2:\n",
    "    model.add(Conv2D(64, kernel_size= (2,2), activation='relu', padding='same'))\n",
    "    \n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Convolution 3\n",
    "    model.add(Conv2D(128, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #Convolution 4\n",
    "    model.add(Conv2D(264, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #Max-Pool 2\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2DTranspose(264, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    \n",
    "    model.add(UpSampling2D(size=(3,3)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    model.add(UpSampling2D(size=(3,3)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(1, kernel_size= (3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss= keras.losses.mean_squared_error, optimizer= 'adam' , metrics=[my_iou_metric])\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = simple_cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
